import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import gaussian_filter
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# === Synthetic LSMC Exercise Region ===
F = 100
K_vals = np.linspace(60, 140, 60)
T_vals = np.linspace(0.05, 1.0, 60)
K_grid, T_grid = np.meshgrid(K_vals, T_vals)
log_moneyness = np.log(K_grid / F)

# Define raw LSMC-styled region with noise
exercise_freq = ((log_moneyness > 0.15) & (T_grid > 0.6)).astype(float)
exercise_freq += np.random.normal(0, 0.1, size=exercise_freq.shape)
exercise_freq = np.clip(exercise_freq, 0, 1)
exercise_smooth = gaussian_filter(exercise_freq, sigma=1)

# === Prepare Training Data ===
X = np.column_stack([log_moneyness.flatten(), T_grid.flatten()])
y = exercise_smooth.flatten()
X_tensor = torch.tensor(X, dtype=torch.float32)
y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)
dataset = TensorDataset(X_tensor, y_tensor)
loader = DataLoader(dataset, batch_size=128, shuffle=True)

# === Neural Net for Exercise Region ===
class PolicyNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2, 64), nn.ReLU(),
            nn.Linear(64, 64), nn.ReLU(),
            nn.Linear(64, 1), nn.Sigmoid()
        )
    def forward(self, x): return self.net(x)

device = torch.device("cpu")
model = PolicyNet().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.01)
loss_fn = nn.BCELoss()

# === Train ===
for epoch in range(300):  # increase to 500+ for better results
    for xb, yb in loader:
        pred = model(xb)
        loss = loss_fn(pred, yb)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

# === Predict on Full Grid ===
with torch.no_grad():
    preds = model(X_tensor).cpu().numpy().reshape(K_grid.shape)
residual = exercise_smooth - preds

# === Plot ===
fig = plt.figure(figsize=(18, 6))
fig.suptitle("LSMC-Based Optimal Stopping Policy â†’ NN Fit", fontsize=15)

# LSMC
ax1 = fig.add_subplot(1, 3, 1, projection='3d')
ax1.plot_surface(log_moneyness, T_grid, exercise_smooth, cmap="viridis")
ax1.set_title("Raw LSMC Exercise Frequency")
ax1.set_xlabel("log(K/F)"); ax1.set_ylabel("T"); ax1.set_zlabel("Density")

# NN
ax2 = fig.add_subplot(1, 3, 2, projection='3d')
ax2.plot_surface(log_moneyness, T_grid, preds, cmap="plasma")
ax2.set_title("NN Predicted Exercise Region")
ax2.set_xlabel("log(K/F)"); ax2.set_ylabel("T"); ax2.set_zlabel("Prob(Exercise)")

# Residual
ax3 = fig.add_subplot(1, 3, 3, projection='3d')
ax3.plot_surface(log_moneyness, T_grid, residual, cmap="coolwarm")
ax3.set_title("Residual (LSMC - NN)")
ax3.set_xlabel("log(K/F)"); ax3.set_ylabel("T"); ax3.set_zlabel("Residual")

plt.tight_layout()
plt.show()
